---
title: "Backtest Algorithm"
author: "Ritesh Pendekanti"
date: "November 28, 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Load Data (Nothing to do here)
```{r}
library(tidyverse)
library(tidyquant)  

options("getSymbols.warning4.0"=FALSE)
options("getSymbols.yahoo.warning"=FALSE)
getSymbols(c("INTC", "DIS", "AMZN", "TSLA"), from = '2019-08-01',
           to = "2020-11-15",warnings = FALSE,
           auto.assign = TRUE)

### My local path of my data folder. Change to yours.
my_path <- "C:\\Users\\Ritesh Pendekanti\\Desktop\\fall_2020\\stats_140sl\\final_proj\\data"

### Merge with Amazon sentiment
amzn <- as.data.frame(AMZN)
amzn$Date <- as.Date(row.names(amzn))
reddit_comments <- read.csv(paste0(my_path,"\\amazon\\amazon_clean_comments.csv"))
reddit_comments$Date <- date(as_datetime(reddit_comments$created_utc))
reddit_comments$weighted_sentiment <- reddit_comments$score * reddit_comments$sentiment
reddit_comments_df <- aggregate(weighted_sentiment ~ Date, data = reddit_comments, mean)
amazon_df <- merge(reddit_comments_df[,c('Date', 'weighted_sentiment')], amzn, by = 'Date')

### Merge with Disney sentiment
dis <- as.data.frame(DIS)
dis$Date <- as.Date(row.names(dis))
reddit_comments <- read.csv(paste0(my_path,"\\disney\\disney_clean_comments.csv"))
reddit_comments$Date <- date(as_datetime(reddit_comments$created_utc))
reddit_comments$weighted_sentiment <- reddit_comments$score * reddit_comments$sentiment
reddit_comments_df <- aggregate(weighted_sentiment ~ Date, data = reddit_comments, mean)
disney_df <- merge(reddit_comments_df[,c('Date', 'weighted_sentiment')], dis, by = 'Date')

### Merge with Intel sentiment
intc <- as.data.frame(INTC)
intc$Date <- as.Date(row.names(intc))
reddit_comments <- read.csv(paste0(my_path,"\\intel\\intel_clean_comments.csv"))
reddit_comments$Date <- date(as_datetime(reddit_comments$created_utc))
reddit_comments$weighted_sentiment <- reddit_comments$score * reddit_comments$sentiment
reddit_comments_df <- aggregate(weighted_sentiment ~ Date, data = reddit_comments, mean)
intel_df <- merge(reddit_comments_df[,c('Date', 'weighted_sentiment')], intc, by = 'Date')

### Merge with Tesla sentiment
tsla <- as.data.frame(TSLA)
tsla$Date <- as.Date(row.names(tsla))
reddit_comments <- read.csv(paste0(my_path,"\\tesla\\tesla_clean_comments.csv"))
reddit_comments$Date <- date(as_datetime(reddit_comments$created_utc))
reddit_comments$weighted_sentiment <- reddit_comments$score * reddit_comments$sentiment
reddit_comments_df <- aggregate(weighted_sentiment ~ Date, data = reddit_comments, mean)
tesla_df <- merge(reddit_comments_df[,c('Date', 'weighted_sentiment')], tsla, by = 'Date')

rm(reddit_comments)
rm(reddit_comments_df)


getSymbols(c("INTC", "DIS", "AMZN", "TSLA"), from = '2018-08-01',
           to = "2020-11-15",warnings = FALSE,
           auto.assign = TRUE)

if(exists("amazon_df") & exists("disney_df") & exists("intel_df") & exists("tesla_df")){
  print("Successfully loaded data for automating MA.")
}
```

## 2. Load functions
```{r}
source('backtest_algo.R')
source('automate_ma.R')
```


## 3. Run algorithm on different possibilities.
```{r}
collected_data <- data.frame(
  stock = character(),
  price_ma = character(),
  price_window = integer(),
  sentiment_ma = character(),
  sentiment_window = character(),
  return_percent = numeric()
)

windows <- seq(5,50,by=5)
stocks <- c("Amazon", "Disney", "Intel", "Tesla")
ma <- c("SMA", "WMA", "EMA")

for(s in stocks){
  for(w in windows){
    for(m in ma){
      
      # Get relevant DF
      if(s == 'Amazon'){
        stock_df <- amazon_df
        price_df <- AMZN
      } else if(s == 'Disney'){
        stock_df <- disney_df
        price_df <- DIS
      } else if(s == 'Intel'){
        stock_df <- intel_df
        price_df <- INTC
      } else if(s == 'Tesla'){
        stock_df <- tesla_df
        price_df <- TSLA
      }
      
      # Use sentiment MA for all possibilities
      t1 <- get_intersections_sentiment(stock_df, ma_type = m, n = w)
      t1_res <- backTest(price_df, t1)
      new_entry <- data.frame(stock = s, price_ma = NA, price_window = NA,
                              sentiment_ma = m, sentiment_window = w, 
                              return_percent = t1_res)
      collected_data <- rbind(collected_data, new_entry)
        
      # Use price MA for all possibilities
      t2 <- get_intersections_prices(stock_df, ma_type = m , n = w)
      t2_res <- backTest(price_df, t2)
      new_entry <- data.frame(stock = s, price_ma = m, price_window = w,
                              sentiment_ma = NA, sentiment_window = NA, 
                              return_percent = t2_res)
      collected_data <- rbind(collected_data, new_entry)
        
      # Use both on all possibilities
      t3 <- merge(t1, t2)
      t3_res <- backTest(price_df, t3)
      new_entry <- data.frame(stock = s, price_ma = m, price_window = w,
                              sentiment_ma = m, sentiment_window = w, 
                              return_percent = t3_res)
      collected_data <- rbind(collected_data, new_entry)
    }
  }
}
```

```{r}
#test <- scale_sentiment(tesla_df, TSLA)
t1 <- get_intersections_sentiment(tesla_df, TSLA, w1=5, w2=120)
t2 <- get_intersections_prices(tesla_df)
backTest(TSLA, t1)
backTest(TSLA, t2)
backTest(TSLA, merge(t1, t2))

t1 <- get_intersections_sentiment(disney_df, DIS, w1=5, w2=120)
t2 <- get_intersections_prices(disney_df)
backTest(DIS, t1)
backTest(DIS, t2)
backTest(DIS, merge(t1, t2))

t1 <- get_intersections_sentiment(intel_df, INTC, w1=6, w2=120)
t2 <- get_intersections_prices(intel_df)
backTest(INTC, t1)
backTest(INTC, t2)
backTest(INTC, merge(t1, t2))

amazon_df <- amazon_df[1:235,]
t1 <- get_intersections_sentiment(amazon_df, AMZN, w1=5, w2=120)
t2 <- get_intersections_prices(amazon_df)
backTest(AMZN, t1)
backTest(AMZN, t2)
backTest(AMZN, merge(t1, t2))
```

## Export collected data as CSV
```{r}
write.csv(collected_data,"return_data.csv", row.names = TRUE)
```
